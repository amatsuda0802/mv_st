このコードは、離散確率分布からサンプリングするための2つの関数を定義しています。具体的には、`sample_discrete_distribution` と `gather_discrete_topk` の2つの関数です。以下に、それぞれの関数の詳細を説明します。

### インポート部分
```python
import torch
from einops import reduce
from jaxtyping import Float, Int64
from torch import Tensor
```
- **torch**: PyTorchの主要なライブラリ。
- **einops**: テンソルの操作を簡潔に行うためのライブラリ。
- **jaxtyping**: JAXと互換性のある型ヒントを提供するライブラリ。
- **Tensor**: PyTorchのテンソル型を表します。

### `sample_discrete_distribution` 関数
```python
def sample_discrete_distribution(
    pdf: Float[Tensor, "*batch bucket"],
    num_samples: int,
    eps: float = torch.finfo(torch.float32).eps,
) -> tuple[
    Int64[Tensor, "*batch sample"],  # index
    Float[Tensor, "*batch sample"],  # probability density
]:
```
- **引数**:
  - `pdf`: 確率密度関数（Probability Density Function）のテンソル。形状は `(*batch, bucket)` です。
  - `num_samples`: サンプリングする数。
  - `eps`: ゼロ除算を防ぐための小さな値（デフォルトは `torch.float32` の最小値）。

#### 処理内容
1. **正規化**:
   ```python
   normalized_pdf = pdf / (eps + reduce(pdf, "... bucket -> ... ()", "sum"))
   ```
   - PDFを正規化します。`reduce` を使用して、各バッチのバケットの合計で割ります。

2. **累積分布関数 (CDF) の計算**:
   ```python
   cdf = normalized_pdf.cumsum(dim=-1)
   ```

3. **サンプリング**:
   ```python
   samples = torch.rand((*batch, num_samples), device=pdf.device)
   index = torch.searchsorted(cdf, samples, right=True).clip(max=bucket - 1)
   ```
   - 一様分布からサンプリングを行い、CDFに対して逆変換サンプリングを行います。

4. **結果の返却**:
   ```python
   return index, normalized_pdf.gather(dim=-1, index=index)
   ```
   - サンプリングされたインデックスと、そのインデックスに対応する確率密度を返します。

### `gather_discrete_topk` 関数
```python
def gather_discrete_topk(
    pdf: Float[Tensor, "*batch bucket"],
    num_samples: int,
    eps: float = torch.finfo(torch.float32).eps,
) -> tuple[
    Int64[Tensor, "*batch sample"],  # index
    Float[Tensor, "*batch sample"],  # probability density
]:
```
- **引数**:
  - `pdf`: 確率密度関数（Probability Density Function）のテンソル。形状は `(*batch, bucket)` です。
  - `num_samples`: トップkのサンプル数。
  - `eps`: ゼロ除算を防ぐための小さな値（デフォルトは `torch.float32` の最小値）。

#### 処理内容
1. **正規化**:
   ```python
   normalized_pdf = pdf / (eps + reduce(pdf, "... bucket -> ... ()", "sum"))
   ```

2. **トップkインデックスの取得**:
   ```python
   index = pdf.topk(k=num_samples, dim=-1).indices
   ```

3. **結果の返却**:
   ```python
   return index, normalized_pdf.gather(dim=-1, index=index)
   ```
   - トップkのインデックスとその確率密度を返します。

### 全体の動作
これらの関数は、離散確率分布からサンプリングしたり、確率密度関数のトップkを取得したりするのに役立ちます。特に、機械学習や統計モデリングの文脈で使用されることが多いです。

### 使い方の例
以下のようにして使うことができます。

```python
pdf = torch.tensor([[0.1, 0.2, 0.7], [0.3, 0.4, 0.3]])
num_samples = 2

# サンプリング
indices, probabilities = sample_discrete_distribution(pdf, num_samples)
print("Sampled indices:", indices)
print("Sampled probabilities:", probabilities)

# トップkを取得
topk_indices, topk_probabilities = gather_discrete_topk(pdf, num_samples)
print("Top-k indices:", topk_indices)
print("Top-k probabilities:", topk_probabilities)
```

この例では、確率密度関数からサンプリングし、トップkのインデックスを取得する方法を示しています。